{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edeed576-3802-4826-a8d7-f011100c1635",
   "metadata": {},
   "source": [
    "# Predict User Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8ef69a-544f-4c46-8ba9-eeb4b52ea749",
   "metadata": {},
   "source": [
    "Load Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d2553a-f40d-47f2-a50c-a341d88066aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os\n",
    "\n",
    "countries = ['Ecuador', 'Bolivia', 'Colombia', 'Chile']\n",
    "\n",
    "COUNTRY = countries[3]\n",
    "\n",
    "## Global Parameters\n",
    "MAX_SEQ_LEN, MAX_TW_LEN = 128, 15\n",
    "BATCH_SIZE = 64\n",
    "SEED = 1911\n",
    "INTERACTION_TYPES = ['<cls>', '<pad>', 'Original', 'Quote', 'Reply', 'Retweet']\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4715caba-6817-4a1a-8db7-bcabf0d5f984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at E:\\OneDrive\\Research Group\\Papers\\Sudaka_BETO\\Data\\ROP_Task\\RoBETO_Model were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from UserModules.ModelConfiguration import *\n",
    "from UserModules.UserClassifier import User_Stance_Classifier\n",
    "\n",
    "tweet_enc_args = {\n",
    "    'Model_Dir': r'E:\\OneDrive\\Research Group\\Papers\\Sudaka_BETO\\Data\\ROP_Task\\RoBETO_Model', \n",
    "    'dropout': 0.1,\n",
    "    'activation': 'Tanh',\n",
    "    'freeze_bert_embeddings': True\n",
    "}\n",
    "\n",
    "tweetConfig = RoBERTaEncoderConfig(**tweet_enc_args)\n",
    "\n",
    "emb_params = {\n",
    "    'cls_idx': INTERACTION_TYPES.index('<cls>'),\n",
    "    'pad_idx': INTERACTION_TYPES.index('<pad>'),\n",
    "    'max_tweet_number': MAX_TW_LEN,\n",
    "    'dropout': 0.1,\n",
    "    'layer_norm_eps': 1e-12,\n",
    "    'tweet_type_number': len(INTERACTION_TYPES),\n",
    "    'mask_embeddings': True\n",
    "}\n",
    "\n",
    "embConfig = ModelEmbeddingsConfig(tweetConfig, **emb_params)\n",
    "\n",
    "user_params = { # This are the default parameters in UserEncoderConfig\n",
    "    'num_attention_heads': 6,\n",
    "    'intermidiate_size': 2048,\n",
    "    'num_encoder_layers': 3,\n",
    "    'transformer_activation': 'gelu',\n",
    "    'user_activation': 'Tanh',\n",
    "    'dropout': 0.1, \n",
    "    'initializer_range': 0.02,\n",
    "    'model_embedder_version': 'v3' # v3 leaves the CLS parameter for the type embeddings    \n",
    "}\n",
    "userConfig = UserEncoderConfig(embConfig, **user_params)\n",
    "\n",
    "# Instantiate model\n",
    "model = User_Stance_Classifier(num_classes = 2, user_config = userConfig)    \n",
    "model.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6366a49f-d134-492a-8e6f-227e15c44534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== E:\\OneDrive\\Research Group\\Papers\\Target_Stance_Classification\\Results\\Best_Models\\Chile\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.001947219159196558"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dir = r'\\{}'.format(COUNTRY)\n",
    "\n",
    "state_dict = torch.load(os.path.join(best_dir, 'model_results.pth'), map_location=device)\n",
    "print(f'Model loaded from <== {best_dir}')\n",
    "\n",
    "model.load_state_dict(state_dict['model_state_dict'])\n",
    "state_dict['valid_loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e91891-00a6-4bf6-abfa-4fe5d47e6c09",
   "metadata": {},
   "source": [
    "Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bba0cf6e-d76d-4b3a-8542-37a1acb0368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT Tokenizer\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import RobertaModel, RobertaTokenizerFast, AdamW, get_linear_schedule_with_warmup, BertForSequenceClassification\n",
    "import torch, numpy as np, random, os\n",
    "from tokenizers.processors import RobertaProcessing, BertProcessing\n",
    "\n",
    "#tokDir = r'/disk1/target_stance_classification/Data/RoBETO/roberta_es_tweet_tokenizer_bpe_50k' #Server Directory\n",
    "tokDir = r'\\RoBETO_Model\\roberta_es_tweet_tokenizer_bpe_50k' #Office Directory\n",
    "\n",
    "tokenizer = RobertaTokenizerFast(os.path.join(tokDir, 'vocab.json'), os.path.join(tokDir, 'merges.txt'), \n",
    "                                tokenizer_file = os.path.join(tokDir, 'es_tweet_tokenizer_bpe_50k.json'), max_len = MAX_SEQ_LEN)\n",
    "# I use this instead of Robertaprocessing as it returns different IDs for the target and reply (it does not follow the Roberta Convention <s>...<\\s><\\s>...<\\s> and uses BERT's  <s>...<\\s>...<\\s>)        \n",
    "tokenizer._tokenizer.post_processor = BertProcessing( \n",
    "                                            (tokenizer.eos_token, tokenizer.eos_token_id),\n",
    "                                            (tokenizer.bos_token, tokenizer.bos_token_id)\n",
    "                                        )\n",
    "PAD_ID, CLS_ID, SEP_ID = tokenizer.pad_token_id, tokenizer.cls_token_id, tokenizer.sep_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899b3ed-69bc-405f-a903-8bb3e50dc6b7",
   "metadata": {},
   "source": [
    "Process Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91590417-4d5a-4bee-b705-b687f8cca0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "def predict(model, data_loader):\n",
    "    model.eval()\n",
    "    resultsDF_list = {'user_id': [], 'true_label': [], 'predicted_label':[]}\n",
    "    embeddings = []\n",
    "    with torch.no_grad():   \n",
    "        epoch_iterator = tqdm(data_loader, desc=\"Predicting\")\n",
    "        for step, batch in enumerate(epoch_iterator):        \n",
    "            # Get Batch Elements\n",
    "            batched_ids, input_ids, attention_mask = batch['batched_ids'], batch['input_ids'].to(device), batch['attention_mask'].to(device)\n",
    "            interaction_types, tweet_masks, labels = batch['interaction_types'].to(device), batch['tweet_masks'].to(device), batch['labels']\n",
    "            \n",
    "            # Predict\n",
    "            logits, user_emb = model(input_ids, attention_mask, interaction_types, tweet_masks) \n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            \n",
    "            # Compile results \n",
    "            embeddings.append(user_emb)\n",
    "            resultsDF_list['user_id'].extend(batched_ids)\n",
    "            if labels is None:\n",
    "                resultsDF_list['true_label'].extend([None] * len(batched_ids))\n",
    "            else:\n",
    "                resultsDF_list['true_label'].extend(list(labels.data.numpy()))\n",
    "            resultsDF_list['predicted_label'].extend(list(preds.data.cpu().numpy()))\n",
    "    embeddings = torch.cat(embeddings)\n",
    "    resultsDF = pd.DataFrame(resultsDF_list)\n",
    "    return resultsDF, embeddings\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4dc293-a3b4-41b0-9bb0-a47643ea8efb",
   "metadata": {},
   "source": [
    "Weak Labeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df24fda-d2c9-40f9-9c41-1924ba056050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Working with File: 2c-test_Chile_dataframe.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ebee8058254285b90e5a8d615cc459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/361 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Working with File: 2b-validation_Chile_dataframe.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98852ee6d6724972bcf0c6470dde1146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Working with File: 2a-train_Chile_dataframe.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91437dbdf1a4199b536c2b0c8d721db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/3208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from UserModules.StanceDataset import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#workDir = r'/disk1/target_stance_classification/Data/Splits/Subsampled' # Server\n",
    "workDir = r'' # Office\n",
    "outDir = r'\\{}'.format(COUNTRY)\n",
    "if not os.path.isdir(outDir):\n",
    "    os.mkdir(outDir)\n",
    "num_workers = 6\n",
    "\n",
    "datasets = {'test': r\"2c-test_{}_dataframe.csv\".format(COUNTRY), 'val': r\"2b-validation_{}_dataframe.csv\".format(COUNTRY), 'train': r\"2a-train_{}_dataframe.csv\".format(COUNTRY)}\n",
    "\n",
    "for key, f in datasets.items():\n",
    "    set_seed(SEED)\n",
    "    print('## Working with File: ' + f)\n",
    "    # Define Training Dataset\n",
    "    stance_params = {\n",
    "        'user_file_name': os.path.join(workDir, f),\n",
    "        'tokenizer': tokenizer,\n",
    "        'interaction_categories': INTERACTION_TYPES,\n",
    "        'max_tw_per_user': MAX_TW_LEN,\n",
    "        'label_column': 'user_government_stance',\n",
    "        'SEED': SEED,\n",
    "        'max_seq_len':MAX_SEQ_LEN\n",
    "    }\n",
    "    dataConfig = StanceDatasetConfig(**stance_params)\n",
    "    data = StanceDataset(dataConfig)\n",
    "    data_loader =  DataLoader(data, batch_size = BATCH_SIZE, num_workers=num_workers, collate_fn = data._Stance_datacollator, shuffle = True)\n",
    "\n",
    "    resultsDF, embeddings = predict(model, data_loader)\n",
    "\n",
    "    # Save Results\n",
    "    resultsDF.to_csv(os.path.join(outDir, '{}_predictions.csv'.format(key)), index = False)\n",
    "    torch.save(embeddings, os.path.join(outDir, '{}_embeddings.pt'.format(key)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7d25689-258e-44c6-acbc-0f8131fe497a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ecuador</th>\n",
       "      <td>94.995262</td>\n",
       "      <td>95.174925</td>\n",
       "      <td>94.987999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bolivia</th>\n",
       "      <td>93.899956</td>\n",
       "      <td>93.973768</td>\n",
       "      <td>94.045637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colombia</th>\n",
       "      <td>95.570011</td>\n",
       "      <td>95.713757</td>\n",
       "      <td>95.615803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chile</th>\n",
       "      <td>95.926491</td>\n",
       "      <td>95.950364</td>\n",
       "      <td>95.975567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train        val       test\n",
       "Ecuador   94.995262  95.174925  94.987999\n",
       "Bolivia   93.899956  93.973768  94.045637\n",
       "Colombia  95.570011  95.713757  95.615803\n",
       "Chile     95.926491  95.950364  95.975567"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd, os\n",
    "\n",
    "\n",
    "countries = ['Ecuador', 'Bolivia', 'Colombia', 'Chile']\n",
    "\n",
    "datasets = ['train', 'val', 'test']\n",
    "resultDF = {}\n",
    "for i, country in enumerate(countries):\n",
    "    workDir = r'\\Main_Predictions\\{}'.format(country)\n",
    "    resultDF[country] = {}\n",
    "    for dt in datasets:\n",
    "        dataDF = pd.read_csv(os.path.join(workDir, '{}_predictions.csv'.format(dt)), dtype = {'user_id': str})\n",
    "        resultDF[country][dt] = (dataDF.true_label == dataDF.predicted_label).sum() / len(dataDF) * 100\n",
    "resultDF = pd.DataFrame.from_dict(resultDF, orient = 'index')\n",
    "resultDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9270e3c6-1582-4873-b002-28c7e4f6b3d7",
   "metadata": {},
   "source": [
    "Unlabeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b22aac-0181-4cf3-9ca9-003eaa9136ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#workDir = r'/disk1/target_stance_classification/Data/Splits/Subsampled' # Server\n",
    "\n",
    "datasets = {'first': r\"2-{}_first_neighbor_df.csv\".format(COUNTRY), 'second': r\"2-{}_second_neighbor_df.csv\".format(COUNTRY)}\n",
    "num_workers = 6\n",
    "for key, f in datasets.items():\n",
    "    set_seed(SEED)\n",
    "    print('## Working with File: ' + f)\n",
    "    # Define Training Dataset\n",
    "    stance_params = {\n",
    "        'user_file_name': os.path.join(workDir, f),\n",
    "        'tokenizer': tokenizer,\n",
    "        'interaction_categories': INTERACTION_TYPES,\n",
    "        'max_tw_per_user': MAX_TW_LEN,\n",
    "        'label_column': None,\n",
    "        'max_seq_len':MAX_SEQ_LEN\n",
    "    }\n",
    "      \n",
    "    dataConfig = StanceDatasetConfig(**stance_params)\n",
    "    data = StanceDataset(dataConfig)\n",
    "    data_loader =  DataLoader(data, batch_size = BATCH_SIZE, num_workers=num_workers, collate_fn = data._Stance_datacollator, shuffle = True)\n",
    "\n",
    "    resultsDF, embeddings = predict(model, data_loader)\n",
    "\n",
    "    # Save Results\n",
    "    resultsDF.to_csv(os.path.join(outDir, '{}_neighbor_predictions.csv'.format(key)), index = False)\n",
    "    torch.save(embeddings, os.path.join(outDir, '{}_neighbor_embeddings.pt'.format(key)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde13349-9cba-4f19-b14c-2d4e585bf971",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
